ARG TAG=develop
FROM hysds/base:${TAG}

MAINTAINER Gerald Manipon (pymonger) "pymonger@gmail.com"
LABEL description "CUDA Base HySDS image"

# Set user and group
ENV USER ops
ENV GROUP ops

# get org and branch
ARG ORG
ARG BRANCH

# add latest repo version to invalidate cache
ADD https://api.github.com/repos/${ORG}/puppet-hysds_base/git/refs/heads/${BRANCH} version.json

# install latest NVIDIA drivers - not supported by p2.xlarge instance type
#RUN set -ex \
# && sudo dnf config-manager --add-repo \
#    https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repo \
# && sudo dnf install kernel-devel kernel-headers -y \
# && sudo dnf install nvidia-driver nvidia-settings -y \
# && sudo dnf install cuda-driver -y

# install older NVIDIA drivers - supported by p2.xlarge instance type
ENV NVARCH x86_64
ENV NVIDIA_REQUIRE_CUDA "cuda>=11.4 brand=tesla,driver>=418,driver<419 brand=tesla,driver>=440,driver<441 brand=tesla,driver>=450,driver<451"
ENV NV_CUDA_CUDART_VERSION 11.4.108-1

COPY files/cuda.repo-x86_64 /etc/yum.repos.d/cuda.repo

USER root

RUN curl -fsSL https://developer.download.nvidia.com/compute/cuda/repos/rhel8/${NVARCH}/D42D0685.pub | sed '/^Version/d' > /etc/pki/rpm-gpg/RPM-GPG-KEY-NVIDIA
RUN more /etc/pki/rpm-gpg/RPM-GPG-KEY-NVIDIA

RUN NVIDIA_GPGKEY_SUM=d1be581509378368edeec8c1eb2958702feedf3bc3d17011adbf24efacce4ab5 && \
    curl -fsSL https://developer.download.nvidia.com/compute/cuda/repos/rhel8/${NVARCH}/D42D0685.pub | sed '/^Version/d' > /etc/pki/rpm-gpg/RPM-GPG-KEY-NVIDIA && \
    echo "$NVIDIA_GPGKEY_SUM  /etc/pki/rpm-gpg/RPM-GPG-KEY-NVIDIA" | sha256sum -c --strict -

ENV CUDA_VERSION 11.4.2

# For libraries in the cuda-compat-* package: https://docs.nvidia.com/cuda/eula/index.html#attachment-a
RUN dnf upgrade -y && dnf install -y \
    cuda-cudart-11-4-${NV_CUDA_CUDART_VERSION} \
    cuda-compat-11-4 \
    && ln -s cuda-11.4 /usr/local/cuda \
    && dnf clean all \
    && rm -rf /var/cache/dnf/*

# nvidia-docker 1.0
RUN echo "/usr/local/nvidia/lib" >> /etc/ld.so.conf.d/nvidia.conf && \
    echo "/usr/local/nvidia/lib64" >> /etc/ld.so.conf.d/nvidia.conf

ENV PATH /usr/local/nvidia/bin:/usr/local/cuda/bin:${PATH}
ENV LD_LIBRARY_PATH /usr/local/nvidia/lib:/usr/local/nvidia/lib64

# nvidia-container-runtime
ENV NVIDIA_VISIBLE_DEVICES all
ENV NVIDIA_DRIVER_CAPABILITIES compute,utility

ENV NV_CUDA_LIB_VERSION 11.4.2-1

ENV NV_NVTX_VERSION 11.4.120-1
ENV NV_LIBNPP_VERSION 11.4.0.110-1
ENV NV_LIBNPP_PACKAGE libnpp-11-4-${NV_LIBNPP_VERSION}
ENV NV_LIBCUBLAS_VERSION 11.6.1.51-1
ENV NV_LIBNCCL_PACKAGE_NAME libnccl
ENV NV_LIBNCCL_PACKAGE_VERSION 2.11.4-1
ENV NV_LIBNCCL_VERSION 2.11.4
ENV NCCL_VERSION 2.11.4
ENV NV_LIBNCCL_PACKAGE ${NV_LIBNCCL_PACKAGE_NAME}-${NV_LIBNCCL_PACKAGE_VERSION}+cuda11.4

RUN dnf install -y \
    cuda-libraries-11-4-${NV_CUDA_LIB_VERSION} \
    cuda-nvtx-11-4-${NV_NVTX_VERSION} \
    ${NV_LIBNPP_PACKAGE} \
    libcublas-11-4-${NV_LIBCUBLAS_VERSION} \
    ${NV_LIBNCCL_PACKAGE} \
    && dnf clean all \
    && rm -rf /var/cache/dnf/*

# set default user and workdir
USER $USER
WORKDIR /home/$USER

# set default entrypoint
ENTRYPOINT ["/docker-entrypoint.sh"]
CMD ["/bin/bash", "--login"]
